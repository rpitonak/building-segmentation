# Open Cities AI Challenge: Segmenting Buildings for Disaster Resilience

This repository contains solution for the [Open Cities AI Challenge: Segmenting Buildings for Disaster Resilience](https://www.drivendata.org/competitions/60/building-segmentation-disaster-resilience/page/150/) hosted by [DRIVENDATA](https://www.drivendata.org/).

Whole pipeline is divided into three jupyter notebooks:
  1) [Data pre-processing](/preprocessing.ipynb)
  2) [Training and evaluation of the model](/building_segmentation.ipynb)
  2) [Preparation of the results for submission](/submission.ipynb)


# Credits

I want to give credits to these people/tools which I have used along the way.

* How to prepare [patches of data for training](https://medium.com/@anthropoco/how-to-segment-buildings-on-drone-imagery-with-fast-ai-cloud-native-geodata-tools-ae249612c321).


* [Getting started guide](https://colab.research.google.com/drive/1Fv-80b1m-O-0p1g59NDzD82XdgurWlwa) from [johnowhitaker](https://community.drivendata.org/u/johnowhitaker/summary).

* [Fast.AI](https://docs.fast.ai/)

Google colab notebook was bootstraped using [colab-bootstrap](https://github.com/zaitra/colab-bootstrap) by [Zaitra](https://zaitra.io).

